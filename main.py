''' 
Project Title : Extractive Summarization of Image Extracted Text
Course : Artificial Intelligence and Machine Learning (AIML) 
File Name : main.py
Description :
This is the main notebook - the starting point of the application. 
Input : 
    Dataset :
        A dataset containing image files and corresponding xml files. 
        [The image files are annotated to highlight the textual content by drawing bounding boxes. The bounding boxes are named as BB1, BB2, ...and so on. The co-ordinates of the bounding boxes are saved as an xml file]. 
    Python files:
        A set of pre-compiled python files. These files contain code for, 
        1. performing Optical Character Recognition (OCR) on the textual content in images 
        2. preprocessing the extracted text 
        3. summarization of the extracted text using extractive and abstractive summarization algorithms. 
Output: 
    A table containing the Rogue scores of the summaries generated by extractive algorithms,
    calculated using the abstractive algorithm as a reference. 
'''

# Mounting google drive folder containing dataset and necessary python files
from google.colab import drive
drive.mount('/content/drive')

# Installing required packages 
pip install sumy

pip install transformers

pip install unidecode

pip install word2number

pip install contractions

pip install pandas_read_xml

sudo apt install tesseract-ocr
pip install pytesseract

apt-get install poppler-utils

pip install rouge

import sys
import pandas as pd
sys.path.append('/content/drive/MyDrive/PythonFiles')

# Importing the pre-compiled python files containing text summarization algorithms 
import Word_Frequency
import Tf_Idf
import Text_Rank
import Lex_Rank
import Luhn
import Lsa
import T5_Model

''' After the dataset containing the img and xml file is imported from the drive folder, call the ocr file methods to
1. Crop image based on annotation
2. Extract text from each cropped image
3. Form a dataframe of all extracted text '''

import OCR
import Data_Preprocessing

from rouge import Rouge

filePath = '/content/Data/'

dataframe, fnames_lst = OCR.getting_file_list(filePath)
result_dataframe = OCR.constructing_dataframe_from_xml(dataframe)
text_dataframe = OCR.extract_text_from_image(result_dataframe, fnames_lst, filePath)

pd.set_option('display.max_colwidth', None)
text_dataframe

'''Data Preprocessing of Extracted Text'''

text_dataframe_after_preprocessing = Data_Preprocessing.preprocess_text_in_dataframe(text_dataframe)

pd.set_option('display.max_colwidth', None)
text_dataframe_after_preprocessing

print("Original Text:")
print("Annotation", text_dataframe_after_preprocessing.iloc[0]['Annotation'])
print("Text:", text_dataframe_after_preprocessing.iloc[0]['Text'])
print("Annotation", text_dataframe_after_preprocessing.iloc[1]['Annotation'])
print("Text:", text_dataframe_after_preprocessing.iloc[1]['Text'])

'''Extractive Summarization Algorithms
1. Word Frequency Summarizer
2. Term Frequency - Inverse Document Frequency Summarizer
3. Text Rank Summarizer
4. Lex Rank Summarizer
5. LSA Summarizer
6. Luhn Summarizer '''

num_of_rows = text_dataframe_after_preprocessing.shape[0]

WF = []
for i in range(num_of_rows):
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    lst = Word_Frequency.run_summarization(text_string)
    WF.append(lst)
print(WF)

TFIDF = []
for i in range(num_of_rows):
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    lst = Tf_Idf.run_summarization(text_string)
    TFIDF.append(lst)
print(TFIDF)

TR = []
for i in range(num_of_rows):
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    lst = list(Text_Rank.run_summarization(text_string, 3))
    TR.append((' ').join(lst))
print(TR)

LR = []
for i in range(num_of_rows):   
    lst = []
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    LR_Output = (Lex_Rank.run_summarization(text_string, 3))
    for ele in LR_Output:
        lst.append(str(ele))
    LR.append((' ').join(lst))
print(LR)

LSA = []
for i in range(num_of_rows):   
    lst = []
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    LSA_Output = (Lsa.run_summarization(text_string, 3))
    for ele in LSA_Output:
        lst.append(str(ele))
    LSA.append((' ').join(lst))
print(LSA)

LUHN = []
for i in range(num_of_rows):   
    lst = []
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    LUHN_Output = (Luhn.run_summarization(text_string, 3))
    for ele in LUHN_Output:
        lst.append(str(ele))
    LUHN.append((' ').join(lst))
print(LUHN)

''' Abstractive Summarization
Google AI T5 pretrained summarization mode '''

T5 = []
for i in range(num_of_rows):
    text_string = text_dataframe_after_preprocessing.iloc[i]['Text']
    T5_Output = (T5_Model.run_abstractive_summarization(text_string))
    T5_Output = T5_Output.replace("<pad>", "")
    T5_Output = T5_Output.replace("</s>", "")
    T5.append(T5_Output)
    print("Algorithm: T5")
    print("Anotation:", text_dataframe_after_preprocessing.iloc[i]['Annotation'])
    print("Summary:",T5_Output)
print(T5)

from IPython.display import HTML, display

def set_css():
  display(HTML('''
  <style>
    pre {
        white-space: pre-wrap;
    }
  </style>
  '''))
get_ipython().events.register('pre_run_cell', set_css)

print("Algorithm: T5")
print("Anotation:", text_dataframe_after_preprocessing.iloc[0]['Annotation'])
print("Summary:",T5[0])
print("Anotation:", text_dataframe_after_preprocessing.iloc[1]['Annotation'])
print("Summary:",T5[1])

''' Method to calculate Rouge score
This method compares the model summary (generated by extractive algorithms) with the reference summary (generated by the abstractive algorithm) and generates a score'''

def get_RougeScore(model_Summary, reference_Summary):
      rouge = Rouge()
      return rouge.get_scores(model_Summary, reference_Summary, avg=True)

''' Method to round off the generated Rogue score to 4 decimal places '''
def process(dictionary):
    for element in dictionary.keys():
        for key in dictionary[element]:
            dictionary[element][key] = round(dictionary[element][key], 4)
    return dictionary

''' Calculating and rounding off Rouge scores for the summaries generated by the 6 extractive algorithms'''
WF_Score = TFIDF_Score = TR_Score = LR_Score = LSA_Score = Luhn_Score = 0
WF_Score = process(get_RougeScore(WF, T5))
TFIDF_Score = process(get_RougeScore(TFIDF, T5))
TR_Score = process(get_RougeScore(TR, T5))
LR_Score = process(get_RougeScore(LR, T5))
LSA_Score = process(get_RougeScore(LSA, T5))
Luhn_Score = process(get_RougeScore(LUHN, T5))

''' Arranging all the values in tabular format '''
array = ['Word Frequency', 'TF-IDF', 'Text Rank', 'Lex Rank', 'LSA', 'Luhn']
score = [WF_Score, TFIDF_Score, TR_Score, LR_Score, LSA_Score, Luhn_Score]
rouge = ['rouge-1', 'rouge-2', 'rouge-l']
dictionary = {}
for j in range(len(rouge)):
    dict = {}
    for i in range(len(array)):
        key = array[i]
        value =  score[i][rouge[j]]
        dict[key] = value
    dictionary[rouge[j]] = dict
print(dictionary)

pd.DataFrame.from_dict(dictionary)